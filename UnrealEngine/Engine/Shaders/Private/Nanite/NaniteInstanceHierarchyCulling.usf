// Copyright Epic Games, Inc. All Rights Reserved.

#include "../Common.ush"
#include "../SceneData.ush"
#include "../WaveOpUtil.ush"
#include "../ComputeShaderUtils.ush"
#include "../SceneCulling/SceneCulling.ush"

#include "NaniteCullingCommon.ush"
#include "NaniteCulling.ush"
#include "NaniteDataDecode.ush"
#include "NaniteHZBCull.ush"

#if DEBUG_FLAGS
RWStructuredBuffer<FNaniteStats>		OutStatsBuffer;
#endif

// Occluded cells fed back to post-pass.
RWStructuredBuffer<FOccludedCellDraw> OutOccludedCells;
RWBuffer<uint> OutOccludedCellArgs;

void WriteOccludedCell(FCellDraw InCellDraw, uint OccludedViewMask)
{
	uint OccludedCellOffset = 0;
	WaveInterlockedAddScalarInGroups(OutOccludedCellArgs[3], OutOccludedCellArgs[0], 64, 1, OccludedCellOffset);

	FOccludedCellDraw OccCellDraw;
	OccCellDraw.CellDraw = InCellDraw;
	OccCellDraw.OccludedViewMask = OccludedViewMask;
	OccCellDraw.Pad = 0;
	OutOccludedCells[OccludedCellOffset] = OccCellDraw;
}

StructuredBuffer<FViewDrawGroup> InViewDrawRanges;

// Yet another format 
// TODO: unify/remove paths
RWStructuredBuffer<FInstanceCullingGroupWork> OutInstanceWorkGroups;

// TODO: this used to be the same arg as the post pass instances from the instance culling main pass, but due to a weird bug they are separate, for now.
// Output indirect dispatch args for the following instance culling pass (x will contain all the groups, which matches the array count above).
RWBuffer<uint> OutInstanceWorkArgs;
uint MaxInstanceWorkGroups;

void AppendInstanceCullingWorkGroups(uint ItemChunksOffset, uint NumItemChunks, uint ViewGroupId, uint ActiveViewMask)
{
	uint InstanceGroupsStartOutOffset = 0;
	WaveInterlockedAdd_(OutInstanceWorkArgs[0], NumItemChunks, InstanceGroupsStartOutOffset);

	// TODO: stats?
#if 0// DEBUG_FLAGS
	if ((RenderFlags & NANITE_RENDER_FLAG_WRITE_STATS) != 0u)
	{
#if CULLING_PASS == CULLING_PASS_OCCLUSION_POST
		WaveInterlockedAddScalar( OutStatsBuffer[0].NumPostCellsPostCull, 1 );
#else
		WaveInterlockedAddScalar( OutStatsBuffer[0].NumMainCellsPostCull, 1 );
#endif
	}
#endif
	// Clamp the number of item groups to buffer size.
	uint NumToOutput = min(NumItemChunks, uint(max(0, int(MaxInstanceWorkGroups) - int(InstanceGroupsStartOutOffset))));

	for (uint Index = 0u; Index < NumToOutput; ++Index)
	{
		uint PackedItemChunkDesc = InstanceHierarchyItemChunks[ItemChunksOffset + Index];

		FInstanceCullingGroupWork InstanceCullingGroupWork;
		InstanceCullingGroupWork.ViewGroupId = ViewGroupId;
		InstanceCullingGroupWork.PackedItemChunkDesc = PackedItemChunkDesc;
		InstanceCullingGroupWork.ActiveViewMask = ActiveViewMask;
		InstanceCullingGroupWork.Pad = 0;

		OutInstanceWorkGroups[InstanceGroupsStartOutOffset + Index] = InstanceCullingGroupWork;
	}
}

Buffer<uint> InOccludedCellArgs;
#if CULLING_PASS == CULLING_PASS_OCCLUSION_POST
StructuredBuffer<FOccludedCellDraw> InOccludedCellDraws;
#else
StructuredBuffer<FCellDraw> InCellDraws;
#endif

uint NumCellDraws;

[numthreads(64, 1, 1)]
void HierarchyCellInstanceCull(uint3 GroupId : SV_GroupID, uint GroupIndex : SV_GroupIndex)
{
	const uint DispatchIndex = GetUnWrappedDispatchThreadId(GroupId, GroupIndex, 64);

#if CULLING_PASS == CULLING_PASS_OCCLUSION_POST
	uint NumCellDrawsLocal = InOccludedCellArgs[3];
#else
	uint NumCellDrawsLocal = NumCellDraws;
#endif

#if DEBUG_FLAGS
	if ((RenderFlags & NANITE_RENDER_FLAG_WRITE_STATS) != 0u && DispatchIndex == 0)
	{
#if CULLING_PASS == CULLING_PASS_OCCLUSION_POST
		OutStatsBuffer[0].NumPostHierarchyCellsPreCull = NumCellDrawsLocal;
#else
		OutStatsBuffer[0].NumMainHierarchyCellsPreCull = NumCellDrawsLocal;
#endif
	}
#endif

	if (DispatchIndex < NumCellDrawsLocal)
	{
#if CULLING_PASS == CULLING_PASS_OCCLUSION_POST
		FOccludedCellDraw OccludedCellDraw = InOccludedCellDraws[DispatchIndex];
		FCellDraw CellDraw = OccludedCellDraw.CellDraw;
		const uint InOccludedViewMask = OccludedCellDraw.OccludedViewMask;
#else
		FCellDraw CellDraw = InCellDraws[DispatchIndex];
#endif
		FViewDrawGroup ViewDrawGroup = InViewDrawRanges[CellDraw.ViewGroupId];
		FSceneHiearchyCellData CellData = GetSceneHiearchyCellData(CellDraw.CellId);

#if CULLING_PASS == CULLING_PASS_OCCLUSION_MAIN
		uint OutOccludedViewMask = 0U;
#endif
		uint ActiveViewMask = 0U;
		// Wrt mip views - views, there is no explicit handling here: they are expected to come in a compact range (post view compaction, or from host for non-VSM draws)
		for (uint ViewIndex = 0; ViewIndex < ViewDrawGroup.NumViews; ++ViewIndex)
		{
#if CULLING_PASS == CULLING_PASS_OCCLUSION_POST
			// TODO: loop over set bits instead!
			if ((InOccludedViewMask & (1U << ViewIndex)) == 0U)
			{
				continue;
			}
#endif
			uint ViewId = ViewDrawGroup.FirstView + ViewIndex;

			FNaniteView NaniteView = GetNaniteView(ViewId);

			// Depth clipping should only be disabled with orthographic projections
			const bool bIsOrtho = IsOrthoProjection(NaniteView.ViewToClip);
			const bool bNearClip = (NaniteView.Flags & NANITE_VIEW_FLAG_NEAR_CLIP) != 0u;
			const bool bViewHZB = (NaniteView.Flags & NANITE_VIEW_FLAG_HZBTEST) != 0u;
			const bool bIsViewUncached = (NaniteView.Flags & NANITE_VIEW_FLAG_UNCACHED) != 0u;

			// TODO: Move out of the loop, logically all views in a group should share the preview translation
			// TODO: Make the view compaction pull this data out of the view and store with the group?
			float4x4 LocalToTranslatedWorld = MakeTranslationMatrix(DFFastToTranslatedWorld(CellData.BlockData.WorldPos, NaniteView.PreViewTranslation));
			float4x4 PrevLocalToTranslatedWorld = MakeTranslationMatrix(DFFastToTranslatedWorld(CellData.BlockData.WorldPos, NaniteView.PrevPreViewTranslation));

			FBoxCull Cull;
			Cull.Init(NaniteView, CellData.LocalBoundsCenter, CellData.LocalBoundsExtent, float3(1.0f, 1.0f, 1.0f), LocalToTranslatedWorld, PrevLocalToTranslatedWorld);
			if (CULLING_PASS == CULLING_PASS_OCCLUSION_POST)
			{
				Cull.bSkipCullFrustum = true;
				Cull.bSkipCullGlobalClipPlane = true;
			}

#if CULLING_PASS == CULLING_PASS_OCCLUSION_MAIN
			Cull.Distance();
			Cull.GlobalClipPlane();
#endif
			BRANCH
            if( Cull.bIsVisible )
            {
#if VIRTUAL_TEXTURE_TARGET
                Cull.PageFlagMask = VSM_ALLOCATED_FLAG;
#endif
				// Note: bClampToPageLevel == true means we might test rather large footprints in the HZB, leading to load imbalance
				// TODO: rebalance the work in the workgroup? Spawn more work groups / cell? Implement the top (virtual space) HZB hierarchy?
				const bool bClampToPageLevel = false;
                Cull.FrustumHZB( bClampToPageLevel );
            }

#if CULLING_PASS == CULLING_PASS_OCCLUSION_MAIN
			if( Cull.bWasOccluded )
			{
				OutOccludedViewMask |= 1U << ViewIndex;
			}
#endif

			if( Cull.bIsVisible && !Cull.bWasOccluded )
			{
				ActiveViewMask |= 1U << ViewIndex;
			}
		}
#if CULLING_PASS == CULLING_PASS_OCCLUSION_MAIN
		if( OutOccludedViewMask != 0u)
		{
			WriteOccludedCell(CellDraw, OutOccludedViewMask);
		}
#endif
		if (ActiveViewMask != 0u)
		{
			FCellHeader CellHeader = GetCellHeader(CellDraw.CellId);
			AppendInstanceCullingWorkGroups(CellHeader.ItemChunksOffset, CellHeader.NumItemChunks, CellDraw.ViewGroupId, ActiveViewMask);
		}
	}
}

// Store the uncullable in the regular cell draw array, at the end.
uint NumViewDrawGroups;
uint UncullableItemChunksOffset;
uint UncullableNumItemChunks;

[numthreads(64, 1, 1)]
void AppendUncullableInstanceWork(uint3 GroupId : SV_GroupID, uint GroupIndex : SV_GroupIndex)
{
	const uint ViewGroupId = GetUnWrappedDispatchThreadId(GroupId, GroupIndex, 64);

	if (ViewGroupId < NumViewDrawGroups)
	{
		FViewDrawGroup ViewDrawGroup = InViewDrawRanges[ViewGroupId];
		if (ViewDrawGroup.NumViews > 0u)
		{
			uint ActiveViewMask = (1u << ViewDrawGroup.NumViews) - 1u;

			AppendInstanceCullingWorkGroups(UncullableItemChunksOffset, UncullableNumItemChunks, ViewGroupId, ActiveViewMask);
		}
	}
}


RWBuffer< uint > OutInstanceWorkArgs0;
RWBuffer< uint > OutInstanceWorkArgs1;

[numthreads(1, 1, 1)]
void InitArgs()
{
	OutInstanceWorkArgs0[0] = 0; // group count == x dimension
	OutInstanceWorkArgs0[1] = 1;
	OutInstanceWorkArgs0[2] = 1;
	OutInstanceWorkArgs0[3] = 0; // instance count
	OutInstanceWorkArgs0[4] = 0; // num groups (not the same as x dim because we drive also occluded instances from this indirect call)

#if OCCLUSION_CULLING
	OutOccludedCellArgs[0] = 0; // group count == x dimension
	OutOccludedCellArgs[1] = 1;
	OutOccludedCellArgs[2] = 1;
	OutOccludedCellArgs[3] = 0; // Item count

	OutInstanceWorkArgs1[0] = 0; // group count == x dimension
	OutInstanceWorkArgs1[1] = 1;
	OutInstanceWorkArgs1[2] = 1;
	OutInstanceWorkArgs1[3] = 0; // instance count
	OutInstanceWorkArgs1[4] = 0; // num groups (not the same as x dim because we drive also occluded instances from this indirect call)
#endif
}
